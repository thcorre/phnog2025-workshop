{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Nokia workshop @ PhNOG 2025!","text":"<p>This page is your starting point into the workshop, it should get you familiar with the lab environment provided by Nokia and provide an overview of the suggested sample activities.</p> <p>During this day you will work in groups on the pre-provided lab activities.</p> <p>As long as you have a laptop with the ability to SSH, you should be good to go. </p> <p>It is not mandatory but usage of the VS Code editor with our Containerlab extension will enhance your experience.   </p> <p>Need help, not a problem, pop your hand in the air and we will be there to guide you. </p>"},{"location":"#pre-requisites","title":"Pre-requisites","text":"<p>A list of workshop modules. Each module is a self-contained guide that can be followed independently, but it is recommended to go through them in order if you are new to Containerlab.</p> <p>Use the official slide deck to follow along with the workshop.</p> <ol> <li>Containerlab Installation guide</li> <li>Basics first</li> <li>Dealing with startup config</li> <li>VM-based nodes</li> <li>Container registry</li> <li>Packet capture</li> </ol> <p>Loved this workshop? Let us know in the comments of this LinkedIn post.</p>"},{"location":"#lab-environment","title":"Lab Environment","text":"<p>For this workshop each group of participants will receive their own dedicated directory running an instance of the lab topology.</p> <p>If everything went according to plan, you should have received a physical piece of paper which contains: - a group ID allocated to your group - SSH credentials to a public cloud instance dedicated to your group.  - HTTPS URL's towards this repo and access to a web based IDE in case you don't have one installed on your operating system.</p> <p>Warning</p> <p>Make sure to backup any code, config, ... offline (e.g your laptop).</p> <p>The public cloud instance will be destroyed once the workshop is concluded.</p>"},{"location":"#group-id","title":"Group ID","text":"<p>Please refer to the paper provided by the workshop session leaders. If nothing has been provided, not a problem, pop your hand in the air and an eager expert will be there to allocate one for you. </p>"},{"location":"#ssh","title":"SSH","text":"<ul> <li>Hostname: refer to the paper provided</li> <li>Username: refer to the paper provided or the slide presented</li> <li>Password: refer to the paper provided or the slide presented</li> </ul> <p>Tip</p> <p>To enable password-less access to an instance, use <code>ssh-keygen -h</code> to generate a public/private key pair and then <code>ssh-copy-id</code> to copy it to the server.</p>"},{"location":"#wifi","title":"WiFi","text":"<p>Details provided in the session.</p>"},{"location":"#pre-provided-activities","title":"Pre-provided activities","text":"<p>Below you can find a table with links towards those pre-provided project which you can use as a baseline for the problem/project you might want to tackle or perform the tasks we've set up for you.</p> <p>The lab comes with a README of its own, please click the link below for more information.</p> Link to pre-provided labs NOS Difficulty DC lab SR Linux Intermediate"},{"location":"#topology","title":"Topology","text":"<p>When accessing your group instance you'll see this repository has already been cloned for you and a fully configured network (powered by containerlab).</p> <p>Will I interfere with other groups?</p> <p>Don't worry: This is your personal group network, you cannot impact any other groups.</p> <p></p> <p>The above topology contains a number of functional blocks to help you in area's you might want to focus on, it contains:</p> <ul> <li>IXP DC lab:<ul> <li>a CLOS model:<ul> <li>2x spines (spine1|spine2) and 3 leaf switches (leaf1|leaf2|leaf3)</li> </ul> </li> </ul> </li> <li>IPv6 BGP unnumbered configured in the underlay</li> <li>DCGW Integration in the DC (dcgw1|dcgw2)</li> <li>Linux clients are attached to both the GRT and VPRN services allowing a full mesh of traffic</li> <li>a fully working telemetry stack (gNMIc/prometheus/grafana)</li> </ul>"},{"location":"#help-ive-bricked-my-lab-how-do-i-redeploy","title":"Help! I've bricked my lab, how do I redeploy?","text":"<p>When accessing your workshop host, you'll see the PhNOG2025 directory is a clone of this repository.</p> <p>The labs covered in this workshops (powered by containerlab), are available for you to use.</p> <p>If you have broken something and would like to restore the state without extensively troubleshooting, you can destroy and redeploy the command via following <code>clab</code> commands:</p> <pre><code>cd $HOME/\nclab destroy -t phnog2025-workshop/dc-lab/dc.phnog2025.clab.yml --cleanup \nclab deploy -t phnog2025-workshop/dc-lab/dc.phnog2025.clab.yml --reconfigure\n</code></pre>"},{"location":"#cloning-this-repository","title":"Cloning this repository","text":"<p>If you would like to work locally on your personal device you should clone this repository. </p> <p>This can be done using one of the following commands below.</p>"},{"location":"#https-recommended","title":"HTTPS (Recommended)","text":"<pre><code>git clone https://github.com/thcorre/phnog2025-workshop.git\n</code></pre>"},{"location":"#ssh_1","title":"SSH","text":"<pre><code>git clone git@github.com:thcorre/phnog2025-workshop.git\n</code></pre>"},{"location":"#github-cli","title":"GitHub CLI","text":"<pre><code>gh repo clone thcorre/phnog2025-workshop\n</code></pre>"},{"location":"#useful-links","title":"Useful links","text":"<ul> <li>Network Developer Portal</li> <li>containerlab</li> <li>gNMIc</li> </ul>"},{"location":"#sr-linux","title":"SR Linux","text":"<ul> <li>Learn SR Linux</li> <li>YANG Browser</li> <li>gNxI Browser</li> </ul>"},{"location":"#misc-toolssoftware","title":"Misc Tools/Software","text":""},{"location":"#windows","title":"Windows","text":"<ul> <li>WSL environment</li> <li>Windows Terminal</li> <li>MobaXterm</li> <li>PuTTY Installer</li> <li>PuTTY Binary</li> </ul>"},{"location":"#macos","title":"MacOS","text":"<ul> <li>iTerm2</li> <li>Warp</li> <li>Hyper</li> <li>Terminal</li> </ul>"},{"location":"#linux","title":"Linux","text":"<ul> <li>Gnome Console</li> <li>Gnome Terminal</li> </ul>"},{"location":"#ides","title":"IDEs","text":"<ul> <li>VS Code</li> <li>VS Code Web</li> <li>Sublime Text</li> <li>IntelliJ IDEA</li> <li>Eclipse</li> <li>PyCharm</li> </ul>"},{"location":"05-install/","title":"Containerlab Installation","text":""},{"location":"05-install/#all-in-one-installer","title":"All In One installer","text":"<p>Installs</p> <ul> <li>docker</li> <li>latest containerlab,</li> <li><code>gh</code> cli</li> </ul> <p>all in one, multi-OS installer:</p> <pre><code>curl -L http://containerlab.dev/setup | \\\nsudo bash -s \"all\"\n</code></pre> <p>The automation script adds the <code>docker</code> group to your <code>user</code>, in order for these changes to take effect, log out from the current session and log back in.</p> <p>Check that docker is installed and running:</p> <pre><code>docker run --rm hello-world\n# Expected output: Hello from Docker!\n</code></pre> <p>Check that containerlab is installed successfully:</p> <pre><code>sudo containerlab version\n</code></pre> <ul> <li>Alternative Containerlab installation options are available here.</li> <li>Alternative Docker installation options can be found here.</li> </ul>"},{"location":"10-basics/","title":"Containerlab Basics","text":"<p>This workshop section introduces you to containerlab basics - topology file, image management workflows and lab lifecycle. It is loosely based on the official Containerlab quickstart.</p>"},{"location":"10-basics/#repository","title":"Repository","text":"<p>The repo should be cloned already and you should be in the <code>ac1-workshop</code> directory as per the output below:</p> <pre><code>[*]\u2500[rd-13]\u2500[~/clab-workshop/10-basics]\n\u2514\u2500\u2500&gt;\n</code></pre>"},{"location":"10-basics/#topology","title":"Topology","text":"<p>The topology file <code>basic.clab.yml</code> defines the lab we are going to use in this basics exercise. It consists of the two nodes:</p> <ul> <li>Nokia SR Linux</li> <li>Arista cEOS</li> </ul> <p>The nodes are interconnected with a single link over their respective first Ethernet interfaces.</p> <pre><code>name: basic\ntopology:\n  nodes:\n    srl:\n      kind: nokia_srlinux\n      image: ghcr.io/nokia/srlinux\n    ceos:\n      kind: arista_ceos\n      image: ceos:4.33.1F\n\n  links:\n    - endpoints: [srl:e1-1, ceos:eth1]\n</code></pre>"},{"location":"10-basics/#deployment","title":"Deployment","text":"<p>Try to deploy the lab:</p> <pre><code>containerlab deploy -t basic.clab.yml\n</code></pre> <p>Note, you can use a shortcut version of the same command - <code>sudo clab dep -t basic.clab.yml</code>.</p> <p>The deployment should succeed.</p>"},{"location":"10-basics/#connecting-to-the-nodes","title":"Connecting to the nodes","text":"<p>Connect to the Nokia SR Linux node using the container name:</p> <pre><code>ssh clab-basic-{GROUP_ID}-srl\n</code></pre> <p>Connect to the cEOS node using its IP address (note, the IP might be different in your lab):</p> <pre><code>ssh admin@172.20.20.3\n</code></pre>"},{"location":"10-basics/#containerlab-hosts-automation","title":"Containerlab hosts automation","text":"<p>Containerlab creates <code>/etc/hosts</code> entries for each deployed lab so that you can access the nodes using their names. Check the entries:</p> <pre><code>cat /etc/hosts\n</code></pre>"},{"location":"10-basics/#containerlab-ssh-config-automation","title":"Containerlab ssh config automation","text":"<p>Containerlab creates ssh config entries in <code>/etc/ssh/ssh_config.d/clab-&lt;lab-name&gt;.conf</code> file to provide easy access to the nodes. Check the entries:</p> <pre><code>cat /etc/ssh/ssh_config.d/clab-basic.conf\n</code></pre>"},{"location":"10-basics/#checking-network-connectivity","title":"Checking network connectivity","text":"<p>SR Linux and cEOS are started with their first Ethernet interfaces connected. Check the connectivity between the nodes:</p> <p>The nodes also come up with LLDP enabled, our goal is to verify that the basic network connectivity is working by inspecting</p> <pre><code>ssh clab-basic-srl\n</code></pre> <p>and checking the LLDP neighbors on ethernet-1/1 interface</p> <pre><code>show /system lldp neighbor interface ethernet-1/1\n</code></pre> <p>The expected output should be:</p> <pre><code>--{ running }--[  ]--\nA:srl# show /system lldp neighbor interface ethernet-1/1\n  +----------+----------+---------+---------+---------+---------+---------+\n  |   Name   | Neighbor | Neighbo | Neighbo | Neighbo | Neighbo | Neighbo |\n  |          |          |    r    |    r    | r First | r Last  | r Port  |\n  |          |          | System  | Chassis | Message | Update  |         |\n  |          |          |  Name   |   ID    |         |         |         |\n  +==========+==========+=========+=========+=========+=========+=========+\n  | ethernet | 00:1C:73 | ceos    | 00:1C:7 | 20      | 16      | Etherne |\n  | -1/1     | :46:95:5 |         | 3:46:95 | hours   | seconds | t1      |\n  |          | C        |         | :5C     | ago     | ago     |         |\n  +----------+----------+---------+---------+---------+---------+---------+\n</code></pre>"},{"location":"10-basics/#listing-running-labs","title":"Listing running labs","text":"<p>When you are in the directory that contains the lab file, you can list the nodes of that lab simply by running:</p> <pre><code>[*]\u2500[rd-13]\u2500[~/clab-workshop/10-basics]\n\u2514\u2500\u2500&gt; sudo containerlab inspect\nINFO[0000] Parsing &amp; checking topology file: basic.clab.yml\n+---+-----------------+--------------+-----------------------+---------------+---------+----------------+----------------------+\n| # |      Name       | Container ID |         Image         |     Kind      |  State  |  IPv4 Address  |     IPv6 Address     |\n+---+-----------------+--------------+-----------------------+---------------+---------+----------------+----------------------+\n| 1 | clab-basic-ceos | c279d892ea22 | ceos:4.32.0F          | arista_ceos   | running | 172.20.20.2/24 | 2001:172:20:20::2/64 |\n| 2 | clab-basic-srl  | 7c46eb454f51 | ghcr.io/nokia/srlinux | nokia_srlinux | running | 172.20.20.3/24 | 2001:172:20:20::3/64 |\n+---+-----------------+--------------+-----------------------+---------------+---------+----------------+----------------------+\n</code></pre> <p>If the topology file is located in a different directory, you can specify the path to the topology file:</p> <pre><code>[*]\u2500[rd-13]\u2500[/tmp]\n\u2514\u2500\u2500&gt; sudo containerlab inspect -t ~/clab-workshop/10-basics/\nINFO[0000] Parsing &amp; checking topology file: basic.clab.yml\n+---+-----------------+--------------+-----------------------+---------------+---------+----------------+----------------------+\n| # |      Name       | Container ID |         Image         |     Kind      |  State  |  IPv4 Address  |     IPv6 Address     |\n+---+-----------------+--------------+-----------------------+---------------+---------+----------------+----------------------+\n| 1 | clab-basic-ceos | c279d892ea22 | ceos:4.32.0F          | arista_ceos   | running | 172.20.20.2/24 | 2001:172:20:20::2/64 |\n| 2 | clab-basic-srl  | 7c46eb454f51 | ghcr.io/nokia/srlinux | nokia_srlinux | running | 172.20.20.3/24 | 2001:172:20:20::3/64 |\n+---+-----------------+--------------+-----------------------+---------------+---------+----------------+----------------------+\n</code></pre> <p>You can also list all running labs regardless of where their topology files are located:</p> <pre><code>[*]\u2500[rd-13]\u2500[~/clab-workshop/10-basics]\n\u2514\u2500\u2500&gt; sudo containerlab inspect --all\n+---+----------------+----------+-----------------+--------------+-----------------------+---------------+---------+----------------+----------------------+\n| # |   Topo Path    | Lab Name |      Name       | Container ID |         Image         |     Kind      |  State  |  IPv4 Address  |     IPv6 Address     |\n+---+----------------+----------+-----------------+--------------+-----------------------+---------------+---------+----------------+----------------------+\n| 1 | basic.clab.yml | basic    | clab-basic-ceos | c279d892ea22 | ceos:4.32.0F          | arista_ceos   | running | 172.20.20.2/24 | 2001:172:20:20::2/64 |\n| 2 |                |          | clab-basic-srl  | 7c46eb454f51 | ghcr.io/nokia/srlinux | nokia_srlinux | running | 172.20.20.3/24 | 2001:172:20:20::3/64 |\n+---+----------------+----------+-----------------+--------------+-----------------------+---------------+---------+----------------+----------------------+\n</code></pre> <p>The output will contain all labs and their nodes.</p> <p>Shortcuts:</p> <ul> <li><code>sudo clab ins</code> == <code>sudo containerlab inspect</code></li> <li><code>sudo clab ins -a</code> == <code>sudo containerlab inspect --all</code></li> </ul>"},{"location":"10-basics/#lab-directory","title":"Lab directory","text":"<p>Lab directory stores the artifacts generated by containerlab that are related to the lab:</p> <ul> <li>tls certificates</li> <li>startup configurations</li> <li>inventory files</li> <li>topology export json file</li> <li>bind mounted directories</li> </ul> <p>To list the contents of the lab directory, run:</p> <pre><code>[*]\u2500[rd-13]\u2500[~/clab-workshop/10-basics]\n\u2514\u2500\u2500&gt; tree -L 3 clab-basic/\n</code></pre>"},{"location":"10-basics/#destroying-the-lab","title":"Destroying the lab","text":"<p>When you are done with the lab, you can destroy it. Containerlab can try and find the <code>*.clab.yml</code> file in the current directory and use it so that you don't have to type it out. Try it:</p> <pre><code>sudo clab des --cleanup\n</code></pre> <p>Alternatively, you could specify the topology file explicitly:</p> <pre><code>sudo clab des -t basic.clab.yml --cleanup\n</code></pre> <p>The <code>--cleanup</code> flag ensures that the lab directory gets removed as well.</p> <p>You finished the basics lab exercise!</p>"},{"location":"15-startup/","title":"Startup configuration","text":"<p>This exercise demonstrates how to provide startup configuration to the lab nodes by means of the <code>startup-config</code> node parameter in the topology file.</p> <p>Startup configuration is a way to provide initial configuration to the lab nodes when they boot up. This is useful when you want to automate the configuration of the nodes and avoid manual intervention. It also brings your lab to a desired state when you need to test a specific scenario.</p> <p>To enter the lab directory, run the following command from anywhere in your terminal:</p> <pre><code>[*]\u2500[rd-13]\u2500[~]\n\u2514\u2500\u2500&gt; cd ~/phnog2025-workshop/15-startup/\n\n[*]\u2500[rd-13]\u2500[~/phnog2025-workshop/15-startup]\n\u2514\u2500\u2500&gt;\n</code></pre> <p>We start by deploying a lab defined in the <code>startup.clab.yml</code> topology file. The lab consists of two nodes: <code>srl</code> (Nokia SR Linux) and <code>ceos</code> (Arista cEOS). Both nodes are configured with a startup configuration file that resides in the same directory as the topology file.</p> <p>We will use the shortened syntax when deploying the lab; less typing and more fun!</p> <pre><code>clab dep -c\n</code></pre> <p>Note, that when calling <code>clab dep -c</code> the containerlab will try to find the <code>*.clab.yml</code> file in the current working directory. If the file is located elsewhere, you can specify the path to the file as an argument to the <code>clab dep</code> command. The <code>-c</code> flag stands for <code>--cleanup</code> and it will ensure that if the lab is already running, it will be stopped and removed before deploying a new one.</p> <p>The startup configuration files - srl.cfg and ceos.cfg - configure the interfaces, IP addressing, loopbacks and BGP peering between SR Linux and cEOS nodes respectively.</p> <p>In particular, the <code>srl</code> node is configured to announce its loopback address <code>10.10.10.1/32</code> towards the <code>ceos</code> node and the <code>ceos</code> node is configured to announce its loopback address <code>10.10.10.2/32</code> towards the <code>srl</code> node.</p> <p>After the lab is deployed, we can expect that the nodes will boot up and apply the startup configuration snippets provided in the topology file. Consequently, it is fair to assume that the nodes will establish BGP peering and exchange routes.</p> <p>Let's connect to the <code>clab-startup-srl</code> node and check the BGP peering status:</p> <pre><code>ssh clab-startup-srl\n</code></pre> <pre><code>--{ running }--[  ]--\nA:srl# show network-instance default protocols bgp neighbor 192.168.1.2\n</code></pre> <p>You should see 1 route sent/received for the aforementioned BGP neighbor.</p> <p>Now, let's connect to the <code>clab-startup-ceos</code> node and make sure that it can reach the loopback address announced by the <code>srl</code> node.</p> <pre><code>ssh clab-startup-ceos\n</code></pre> <p>When in the EOS shell, issue a ping towards the <code>srl</code> node's loopback address:</p> <pre><code>ping 10.10.10.1\n</code></pre> <p>You should see a successful ping response.</p> <p>You have successfully deployed the lab with the nodes equipped with the startup configuration. This is a powerful feature that can be used to provision the nodes with the desired configuration when they boot up.</p>"},{"location":"20-vm/","title":"VM-based nodes in containerlab","text":"<p>Unfortunately not every NOS is available in a native containerized format, and many NOSes of today are still VM-based.</p> <p>However do not fear, as using the vrnetlab we can package these VM-based NOSes into containers so that they can integrate cleanly into Containerlab.</p> <p>Info</p> <p>The vrnetlab used in Containerlab is a fork of the original <code>vrnetlab/vrnetlab</code> project. The original project will not work in contianerlab, you must use the fork which has added extensions for better integration into Containerlab, as well as more supported NOSes.</p> <p>Go to containerlab.dev/vrnetlab to quickly navigate to the fork.</p> <p>Start with cloning the project:</p> <pre><code>cd ~ &amp;&amp; git clone https://github.com/hellt/vrnetlab.git &amp;&amp; \\\ncd ~/vrnetlab\n</code></pre>"},{"location":"20-vm/#building-sonic-container-image","title":"Building SONiC container image","text":"<p>SONiC image (downloaded from sonic.software) is located at <code>~/images/sonic-vm-202411.qcow2</code> on your host and should be copied to the <code>~/vrnetlab/sonic/</code> directory before building the container image.</p> <pre><code>cp ~/images/sonic-vs-202411.qcow2 ~/vrnetlab/sonic/\n</code></pre> <p>Once copied, we can enter in the <code>~/vrnetlab/sonic</code> image and build the container image:</p> <pre><code>cd ~/vrnetlab/sonic-vm &amp;&amp; make\n</code></pre> <p>The resulting image will be tagged as <code>vrnetlab/sonic-vm:202411</code>. This can be verified using <code>docker images</code> command.</p> <pre><code>REPOSITORY                TAG       IMAGE ID       CREATED          SIZE\nvrnetlab/sonic-vm         202411    33b73b1dadc4   5 minutes ago    6.37GB\nceos                      4.33.1F   927c8cd41224   53 minutes ago   2.46GB\nghcr.io/nokia/srlinux     latest    eb2a823cd8ce   8 days ago       2.35GB\n</code></pre>"},{"location":"20-vm/#deploying-the-vm-based-nodes-lab","title":"Deploying the VM-based nodes lab","text":"<p>With the sonic image built, we can proceed with the lab deployment. We will deploy a lab with SONiC and SR Linux to show that Containerlab can have a VM based docker node and a native docker node in the same lab.</p> <p>First, let's switch back to the lab directory:</p> <pre><code>cd ~/innog8-workshop/20-vm\n</code></pre> <p>Now lets deploy the lab:</p> <pre><code>clab dep -c\n</code></pre> <p>At the end of the deployment, the following table will be displayed. Wait for the sonic boot to be completed (see next section), before trying to login to sonic.</p> <pre><code>+---+---------------+--------------+--------------------------------+---------------+---------+----------------+----------------------+\n| # |     Name      | Container ID |             Image              |     Kind      |  State  |  IPv4 Address  |     IPv6 Address     |\n+---+---------------+--------------+--------------------------------+---------------+---------+----------------+----------------------+\n| 1 | clab-vm-sonic | c865295f6b4e | vrnetlab/sonic_sonic-vs:202411 | sonic-vm      | running | 172.20.20.3/24 | 3fff:172:20:20::3/64 |\n| 2 | clab-vm-srl   | 51b41a280f84 | ghcr.io/nokia/srlinux          | nokia_srlinux | running | 172.20.20.2/24 | 3fff:172:20:20::2/64 |\n+---+---------------+--------------+--------------------------------+---------------+---------+----------------+----------------------+\n</code></pre>"},{"location":"20-vm/#monitoring-the-boot-process","title":"Monitoring the boot process","text":"<p>To monitor the boot process of SONiC, you can open a new terminal and run the following command:</p> <pre><code>sudo docker logs -f clab-vm-sonic\n</code></pre> <p>the SONiC boot time is approximately 1 minute.</p>"},{"location":"20-vm/#connecting-to-the-nodes","title":"Connecting to the nodes","text":"<p>To connect to SONiC node:</p> <pre><code>ssh admin@clab-vm-sonic\n</code></pre> <p>Refer to the password in your card.</p> <p>To connect to SR Linux node:</p> <pre><code>ssh clab-vm-srl\n</code></pre>"},{"location":"20-vm/#configuring-the-nodes","title":"Configuring the nodes","text":"<p>Our goal is establish a ping between SR Linux and SONiC devices.</p> <p>The SONiC device is pre-configured with the link IP address. This can be verified using:</p> <pre><code>show runningconfiguration interfaces\n</code></pre> <p>For reference, here is the configuration for sonic interface <code>Ethernet0</code>:</p> <pre><code>sudo config interface ip add Ethernet0 10.0.0.0/31\nsudo config interface startup Ethernet0\n</code></pre> <p>Login to SR Linux node and run <code>enter candidate</code> to get into configuration edit mode and paste the below lines to configure the interface:</p> <p><pre><code>set / interface ethernet-1/1 admin-state enable\nset / interface ethernet-1/1 subinterface 0 ipv4 admin-state enable\nset / interface ethernet-1/1 subinterface 0 ipv4 address 10.0.0.1/31\nset / network-instance default type default\nset / network-instance default interface ethernet-1/1.0\n</code></pre> Once configured issue the <code>commit now</code> command to make sure the candidate config is merged into running.</p> <p>Now we configured the two systems to be able to communicate with each other. Perform a ping from SONiC to SR Linux:</p> <pre><code>admin@sonic:~$ ping 10.0.0.1 -c 3\nPING 10.0.0.1 (10.0.0.1) 56(84) bytes of data.\n64 bytes from 10.0.0.1: icmp_seq=1 ttl=64 time=2.00 ms\n64 bytes from 10.0.0.1: icmp_seq=2 ttl=64 time=1.97 ms\n64 bytes from 10.0.0.1: icmp_seq=3 ttl=64 time=3.17 ms\n\n--- 10.0.0.1 ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 2003ms\nrtt min/avg/max/mdev = 1.965/2.378/3.168/0.558 ms\n</code></pre> <p>We have now completed the section on bring VM based nodes into Containerlab.</p>"},{"location":"30-registry/","title":"Container registry and Containerlab","text":"<p>Containerlab is better when used with a container registry. No one loved to witness the uncontrolled proliferation of unversioned disk image (qcow2, vmdk) files shared via ftps, one drives and IM attachments.</p> <p>We can do better!</p> <p>Since containerlab deals with container images, it is natural to use a container registry to store them. Versioned, immutable, tagged and easily shareable with granular access control.</p> <p>Whether you choose to use one of the public registries or a run a private one, the workflow is the same. Let's see what it looks like.</p>"},{"location":"30-registry/#harbor-registry","title":"Harbor registry","text":"<p>In this workshop we make use of an open-source registry called Harbor. It is a CNCF graduated project and is a great choice for a private registry.</p> <p>The registry has been already deployed in the workshop environment, but it is quite easy to deploy yourself in your own organization. It is a single docker compose stack that can be deployed in a few minutes.</p> <p>The Harbor registry offers a neat Web UI to browse the registry contents, manage users and tune access control. You can log in to the registry UI through the public IP address of the Bare Metal host (porovided during the workshop) using the <code>admin</code> user and the password available in your workshop handout.</p> <p>When logged in as <code>admin</code> you can created users, repositories, browse the registry contents and many more. Managing the harbor registry is out of the scope of this workshop.</p>"},{"location":"30-registry/#listing-images-from-the-registry","title":"Listing images from the registry","text":"<p>You can see the images in the registry UI.</p> <p></p> <p>If you want to get the list of available repositories/tags in the registry, you can use registry API.</p> <p>Listing available repositories:</p> <pre><code>curl -X 'GET'  'https://{public_IP}/api/v2.0/repositories?page=1&amp;page_size=10'  -H 'accept: application/json' -k\n</code></pre>"},{"location":"30-registry/#using-images-from-the-registry","title":"Using images from the registry","text":"<p>The whole point of pushing the image to the registry is to be able to use it in the future yourself and also to share it with others. And now that we have the image in the registry, we can modify the <code>20-vm.clab.yml</code> file to make use of it:</p> <pre><code>name: vm\ntopology:\n  nodes:\n    sonic:\n      kind: sonic-vm\n      image: {public_IP}/library/sonic-vm:202411\n\n    srl:\n      kind: nokia_srlinux\n-     image: ghcr.io/nokia/srlinux:25.3.3\n+     image: {public_IP}/library/nokia_srlinux:25.3.3\n\n  links:\n    - endpoints: [\"sonic:eth1\", \"srl:e1-1\"]\n</code></pre> <p>Not only this gives us an easy way to share images with others, but also it enables stronger reproducibility of the lab, as the users of our lab would use exactly the same image that we built.</p>"},{"location":"40-packet-capture/","title":"Packet capture","text":"<p>Every lab emulation software must provide its users with the packet capturing abilities. Looking at the frames as they traverse the network links is not only educational, but also helps to troubleshoot the issues that might arise during the lab development.</p> <p>Containerlab offers a simple way to capture the packets from any interface of any node in the lab since every interface is exposed to the underlying Linux OS. This article will explain how to do that.</p> <p>Everything we are going to do in this exercise is explained in details in the Containerlab documentation.</p>"},{"location":"40-packet-capture/#remote-capture","title":"Remote capture","text":"<p>The first way to capture the packets from a containerlab node running on a remote host that we are going to explore is called \"remote capture\". In this scenario a user has a network connectivity (ssh) to the host that runs containerlab topology and wishes to get the packet capture displayed in the Wireshark running locally.</p> <p>To achieve this, we will execute the <code>tcpdump</code> command on the remote host and pipe the output to the local Wireshark app. Here is a command that does it all for the host <code>d1</code> which is the instructors host.</p> <p>It captures the traffic from SR OS (<code>clab-vm-sros</code>) port <code>eth1</code> (<code>1/1/1</code>) running on <code>d1</code> host and displaying the capture in the Wireshark.</p> <p>The command is provided for WSL and Mac systems, assuming default Wireshark installation path</p> <p>Windows/WSL:</p> <pre><code>ssh root@{public_IP} \\\n\"ip netns exec clab-vm-sros tcpdump -U -nni eth1 -w -\" | \\\n/mnt/c/Program\\ Files/Wireshark/wireshark.exe -k -i -\n</code></pre> <p>macOS:</p> <pre><code>ssh root@{public_IP} \\\n\"ip netns exec clab-vm-sros tcpdump -U -nni eth1 -w -\" | \\\n/Applications/Wireshark.app/Contents/MacOS/Wireshark  -k -i -\n</code></pre>"},{"location":"40-packet-capture/#edgeshark","title":"Edgeshark","text":"<p>Edgeshark is a set of tools that offer (among many things) a Web UI that displays every interface of every container and can start a wireshark as easy as clicking a button.</p> <p>Edgeshark installation consists of two parts:</p> <ol> <li>A service that runs on the host that runs containerlab topologies</li> <li>A wireshark capture plugin that runs next to the Wireshark on a user's PC</li> </ol> <p>To install the service, past the installer command that uses docker compose to deploy the service:</p> <pre><code>curl -sL \\\nhttps://github.com/siemens/edgeshark/raw/main/deployments/wget/docker-compose.yaml | \\\ndocker compose -f - up -d\n</code></pre> <p>Now, you have to install the client plugin based on the OS of your PC.</p>"},{"location":"40-packet-capture/#windows","title":"Windows","text":"<p>Windows users get to enjoy a simple installer-based workflow that installs the URL handler and the Wireshark plugin in one go.</p> <p>Download the installer file - https://github.com/siemens/cshargextcap/releases/download/v0.10.7/cshargextcap_0.10.7_windows_amd64.zip</p> <p>Unzip the archive and launch the installer script.</p>"},{"location":"40-packet-capture/#macos","title":"MacOs","text":"<p>MacOs users have to suffer a little. But it is not that bad either.</p> <p>To install the URL handler paste the following in the Mac terminal app:</p> <pre><code>mkdir -p /tmp/pflix-handler &amp;&amp; cd /tmp/pflix-handler &amp;&amp; \\\nrm -rf packetflix-handler.zip packetflix-handler.app __MACOSX &amp;&amp; \\\ncurl -sLO https://github.com/srl-labs/containerlab/files/14278951/packetflix-handler.zip &amp;&amp; \\\nunzip packetflix-handler.zip &amp;&amp; \\\nsudo mv packetflix-handler.app /Applications\n</code></pre> <p>To install the extpcap wireshark plugin execute in the Mac terminal:</p> <pre><code># for x86_64 MacOS use https://github.com/siemens/cshargextcap/releases/download/v0.10.7/cshargextcap_0.10.7_darwin_amd64.tar.gz\nDOWNLOAD_URL=https://github.com/siemens/cshargextcap/releases/download/v0.10.7/cshargextcap_0.10.7_darwin_arm64.tar.gz\nmkdir -p /tmp/pflix-handler &amp;&amp; curl -sL $DOWNLOAD_URL | tar -xz -C /tmp/pflix-handler &amp;&amp; \\\nopen /tmp/pflix-handler &amp;&amp; open /Applications/Wireshark.app/Contents/MacOS/extcap\n</code></pre> <p>The command above will open two Finder windows, one with the <code>cshargextcap</code> binary and the other with the Wireshark's existing plugins. Move the <code>cshargextcap</code> file over to the window with Wireshark plugins.</p>"},{"location":"40-packet-capture/#web-ui","title":"Web UI","text":"<p>To access the Edgeshark UI, open a browser and navigate to the following URL:</p> <p>http://{public_IP}:5001</p> <p>Note, the http schema is important, since https is not enabled.</p>"},{"location":"dc-lab/","title":"PhNOG 2025 DC Lab","text":"<p>Disclaimer</p> <p>This lab is based on srl-sros-telemetry-lab. (Kudos to Marlon Paz, Roman Dodin and Kevin Todts). </p> <p>We have modified the lab for this workshop to better align with the latest DC best practices (IPv6 underlay infra, Usage of BGP unnumbered underlay with IPv6 link-locals, BFD sessions used on eBGP peers, optimized BGP timers etc.) and to also demonstrate additional EVPN capabilities like All-Active multihoming.</p> <p>This lab represents a small Clos DC fabric with Nokia SR Linux switches running as containers and a DC gateways layer composed by Nokia SROS DC Gateways on a containerized vSIM image (VM-based).</p> <p>Goals of this lab:</p> <ol> <li>Demonstrate how a telemetry stack can be incorporated into the same clab topology file.</li> <li>Explain SR Linux wholistic telemetry support.</li> <li>Provide practical configuration examples for the gnmic collector to subscribe to fabric nodes and export metrics to Prometheus TSDB.</li> </ol>"},{"location":"dc-lab/#deploying-the-lab","title":"Deploying the lab","text":"<p>The lab is deployed with containerlab project where <code>st.clab.yml</code> file declaratively describes the lab topology.</p> <pre><code># deploy a lab\nclab deploy\n</code></pre> <p>Once the lab is completed, it can be removed with the destroy command.</p> <pre><code># destroy a lab\nclab destroy\n</code></pre>"},{"location":"dc-lab/#accessing-the-network-elements","title":"Accessing the network elements","text":"<p>Once the lab has been deployed, the different SR Linux and SROS nodes can be accessed via SSH through their management IP address, given in the table displayed after successful deployment of the Containerlab topology.</p> <p>Tip</p> <p>Instead of using the IP addres to connect to the nodes, you can use the node hostname.</p> <p>For example <pre><code># reach a SR Linux leaf or a spine via SSH\nssh admin@leaf1\nssh admin@spine1\n</code></pre></p> <p>You can't SSH into the linux nodes. You must enter the shell using the <code>docker exec</code> command. Refer to the example below.</p> <pre><code># reach a Linux client via Docker\ndocker exec -it client1 bash\n</code></pre>"},{"location":"dc-lab/#fabric-configuration","title":"Fabric configuration","text":"<p>The DC fabric used in this lab consists of three leaf nodes and two spine nodes interconnected with each other as shown in the diagram.</p> <p></p> <p>Leaf and spine nodes use Nokia SR Linux IXR-D2L and IXR-D3L chassis respectively. Each network element of this topology is equipped with a fabric startup configuration file that is applied at the node's startup.</p> <p>Once booted, network nodes will come up with interfaces, underlay protocols and overlay service configured. The fabric is configured with Layer 2 EVPN service between the leaf nodes.</p>"},{"location":"dc-lab/#verifying-the-underlay-and-overlay-status","title":"Verifying the underlay and overlay status","text":"<p>The underlay network is provided by eBGP, and the overlay network, by iBGP. By connecting via SSH to one of the leaf nodes, it is possible to verify the status of those BGP sessions.</p> <pre><code>A:leaf1# /show network-instance protocols bgp neighbor\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nBGP neighbor summary for network-instance \"default\"\nFlags: S static, D dynamic, L discovered by LLDP, B BFD enabled, - disabled, * slow\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n+------------------------+-----------------------------------+------------------------+--------+-------------+--------------------+--------------------+-----------------+-----------------------------------+\n|        Net-Inst        |               Peer                |         Group          | Flags  |   Peer-AS   |       State        |       Uptime       |    AFI/SAFI     |          [Rx/Active/Tx]           |\n+========================+===================================+========================+========+=============+====================+====================+=================+===================================+\n| default                | 10.0.2.1                          | overlay                | SB     | 64512       | established        | 0d:0h:7m:43s       | evpn            | [9/9/2]                           |\n|                        |                                   |                        |        |             |                    |                    | ipv4-unicast    | [8/2/1]                           |\n|                        |                                   |                        |        |             |                    |                    | ipv6-unicast    | [0/0/0]                           |\n| default                | 10.0.2.2                          | overlay                | SB     | 64512       | established        | 0d:0h:2m:4s        | evpn            | [9/0/2]                           |\n|                        |                                   |                        |        |             |                    |                    | ipv4-unicast    | [7/2/6]                           |\n|                        |                                   |                        |        |             |                    |                    | ipv6-unicast    | [0/0/0]                           |\n| default                | fe80::186c:eff:feff:1%ethernet-   | underlay               | DB     | 65500       | established        | 0d:0h:0m:9s        | evpn            | [0/0/0]                           |\n|                        | 1/49.0                            |                        |        |             |                    |                    | ipv4-unicast    | [5/5/1]                           |\n|                        |                                   |                        |        |             |                    |                    | ipv6-unicast    | [0/0/0]                           |\n| default                | fe80::18a2:fff:feff:1%ethernet-   | underlay               | DB     | 65500       | established        | 0d:0h:0m:6s        | evpn            | [0/0/0]                           |\n|                        | 1/50.0                            |                        |        |             |                    |                    | ipv4-unicast    | [5/5/6]                           |\n|                        |                                   |                        |        |             |                    |                    | ipv6-unicast    | [0/0/0]                           |\n+------------------------+-----------------------------------+------------------------+--------+-------------+--------------------+--------------------+-----------------+-----------------------------------+\nSummary:\n2 configured neighbors, 2 configured sessions are established, 0 disabled peers\n2 dynamic peers\n</code></pre>"},{"location":"dc-lab/#running-traffic","title":"Running traffic","text":"<p>To run test traffic through the fabric, we can leverage <code>traffic.sh</code> control script.</p> <p>To start the traffic:</p> <ul> <li><code>bash traffic.sh start all</code> - start traffic between all nodes</li> <li><code>bash traffic.sh start 1-3</code> - start traffic between client1 and client3</li> <li><code>bash traffic.sh start 2-4</code> - start traffic between client2 and client4</li> </ul> <p>To stop the traffic:</p> <ul> <li><code>bash traffic.sh stop all</code> - stop traffic generation between all nodes</li> <li><code>bash traffic.sh stop 1-3</code> - stop traffic generation between client1 and client3</li> <li><code>bash traffic.sh stop 2-4</code> - stop traffic generation between client2 and client4</li> </ul>"},{"location":"dc-lab/#telemetry-stack","title":"Telemetry stack","text":"<p>SR Linux has first-class streaming telemetry support thanks to 100% YANG coverage of state and config data. </p> <p>The wholistic coverage enables SR Linux users to stream any data off of the NOS with on-change, sample, or target-defined support. A discrepancy in visibility across APIs is not about SR Linux.</p> <p>Telemetry is at the core of this lab. The following stack of software solutions has been chosen for it:</p> Role Software Telemetry collector gnmic Time-Series DB prometheus Visualization grafana"},{"location":"dc-lab/#grafana","title":"Grafana","text":"<p>Grafana is a key component of this lab. The lab topology file includes grafana node along with its configuration parameters such as dashboards, datasources and required plugins.</p> <p>The Grafana dashboard provided by this repository provides multiple views on the collected real-time data. Powered by the flowchart plugin, it overlays telemetry sourced data over graphics such as topology and front panel views of the devices.</p> <p></p> <p>Using the flowchart plugin and real telemetry data users can create interactive topology maps (aka weathermap) with a visual indication of link rate/utilization.</p> <p></p>"},{"location":"dc-lab/#access-details","title":"Access details","text":"<ul> <li>Grafana: http://localhost:3000. Built-in user credentials: <code>admin/admin</code></li> <li>Prometheus: http://localhost:9090/graph</li> </ul>"}]}